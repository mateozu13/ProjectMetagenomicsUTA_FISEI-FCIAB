# OptimizaciÃ³n de Servidor BioinformÃ¡tico para AnÃ¡lisis MetagenÃ³mico

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Rocky Linux](https://img.shields.io/badge/OS-Rocky%20Linux%208.10-green.svg)](https://rockylinux.org/)
[![QIIME2](https://img.shields.io/badge/QIIME2-2024.10-blue.svg)](https://qiime2.org/)

Proyecto de optimizaciÃ³n de infraestructura computacional para el procesamiento y almacenamiento de datos metagenÃ³micos aplicado al diagnÃ³stico de Enfermedades Inflamatorias Intestinales (EII).

**Universidad TÃ©cnica de Ambato**  
Facultad de IngenierÃ­a en Sistemas, ElectrÃ³nica e Industrial  
Trabajo de TitulaciÃ³n - Mateo Zurita

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#-descripciÃ³n)
- [Objetivos](#-objetivos)
- [Requisitos Previos](#-requisitos-previos)
- [InstalaciÃ³n](#-instalaciÃ³n)
  - [Paso 1: ConfiguraciÃ³n Inicial](#paso-1-configuraciÃ³n-inicial)
  - [Paso 2: OptimizaciÃ³n del Sistema](#paso-2-optimizaciÃ³n-del-sistema)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [PreparaciÃ³n de Datos](#-preparaciÃ³n-de-datos)
- [Uso de Pipelines](#-uso-de-pipelines)
  - [Pipeline BÃ¡sico](#pipeline-bÃ¡sico)
  - [Pipeline con Monitoreo de Recursos](#pipeline-con-monitoreo-de-recursos)
  - [Pipeline Optimizado con ParalelizaciÃ³n](#pipeline-optimizado-con-paralelizaciÃ³n)
- [Herramientas Auxiliares](#-herramientas-auxiliares)
- [ConfiguraciÃ³n Personalizada](#-configuraciÃ³n-personalizada)
- [ComparaciÃ³n de Resultados](#-comparaciÃ³n-de-resultados)
- [Optimizaciones Implementadas](#-optimizaciones-implementadas)
- [Resultados](#-resultados)
- [Troubleshooting](#-troubleshooting)
- [Referencias](#-referencias)

---

## ğŸ”¬ DescripciÃ³n

Este proyecto presenta una metodologÃ­a sistemÃ¡tica de optimizaciÃ³n para servidores dedicados al anÃ¡lisis bioinformÃ¡tico de datos metagenÃ³micos, especÃ­ficamente enfocado en el proyecto de investigaciÃ³n **"Estrategias MetagenÃ³micas para caracterizaciÃ³n del microbioma intestinal humano aplicado al diagnÃ³stico precoz y tratamiento personalizado de las Enfermedades Inflamatorias Intestinales (EII)"**.

La optimizaciÃ³n abarca tres niveles:

1. **OptimizaciÃ³n a nivel de kernel** - ParÃ¡metros del sistema operativo
2. **OptimizaciÃ³n de software** - Herramientas de paralelizaciÃ³n y compresiÃ³n
3. **OptimizaciÃ³n de hardware** - ConfiguraciÃ³n HPC y gestiÃ³n de recursos

### Impacto obtenido

- **ReducciÃ³n de tiempo de procesamiento**: 92.7%
- **Mejora en utilizaciÃ³n de CPU**: 45-60%
- **OptimizaciÃ³n de I/O**: Lectura/escritura paralela con pigz

---

## ğŸ’» Requisitos Previos

### Hardware MÃ­nimo Recomendado

- **CPU**: 12+ cores (recomendado: 24 cores)
- **RAM**: 32 GB (recomendado: 64 GB+)
- **Almacenamiento**: 512 GB SSD + 2 TB HDD (opcional)
- **Red**: 1 Gbps (recomendado: 10 Gbps)

### Software

- **Sistema Operativo**: Rocky Linux 8.10 o compatible (RHEL, AlmaLinux)
- **Acceso**: Permisos de root/sudo
- **Conectividad**: Acceso a internet para descargar dependencias

### Conocimientos Previos

- LÃ­nea de comandos de Linux
- Conceptos bÃ¡sicos de bioinformÃ¡tica
- Formato de archivos FASTQ
- (Opcional) Conocimientos de QIIME2

---

## ğŸš€ InstalaciÃ³n

### Paso 1: ConfiguraciÃ³n Inicial

Clone el repositorio y navegue al directorio del proyecto:

```bash
git clone https://github.com/mateozu13/ProjectMetagenomicsUTA_FISEI-FCIAB.git
cd ProjectMetagenomicsUTA_FISEI-FCIAB
```

Los scripts de configuraciÃ³n deben ejecutarse en el siguiente orden:

#### 1.1 InstalaciÃ³n de Conda

```bash
cd configurations
sudo bash install_conda.sh
```

Este script:

- Descarga e instala Miniconda3
- Configura las variables de entorno
- Inicializa conda para bash

**Nota**: Cierre y reabra la terminal despuÃ©s de este paso.

#### 1.2 InstalaciÃ³n de QIIME2

```bash
sudo bash install_qiime2.sh
```

Este script:

- Crea el ambiente conda `qiime2` con la versiÃ³n 2024.10
- Instala todas las dependencias de QIIME2
- Configura el ambiente para anÃ¡lisis metagenÃ³micos

**Tiempo estimado**: 30-45 minutos

#### 1.3 InstalaciÃ³n de Herramientas de Preprocesamiento

```bash
sudo bash install_tools.sh
```

Este script:

- Crea el ambiente conda `preproc`
- Instala fastp para control de calidad de secuencias
- Instala MultiQC para reportes consolidados
- Configura ACLs y permisos para el grupo `research`

#### 1.4 InstalaciÃ³n de Herramientas de OptimizaciÃ³n

```bash
sudo bash install_optimization_tools.sh
```

Este script instala:

- **GNU Parallel**: EjecuciÃ³n paralela de comandos
- **pigz**: CompresiÃ³n/descompresiÃ³n paralela (reemplazo de gzip)
- **Herramientas de monitoreo**: pidstat, iostat, htop, bc

Configuraciones automÃ¡ticas:

- Alias globales (`gzip` â†’ `pigz`)
- Archivo `will-cite` para suprimir advertencias
- Variables de entorno optimizadas

**VerificaciÃ³n**:

```bash
parallel --version
pigz --version
```

---

### Paso 2: OptimizaciÃ³n del Sistema

Estos scripts optimizan el rendimiento del servidor a nivel de kernel y sistema operativo.

#### 2.1 ActivaciÃ³n de Perfil HPC Compute

```bash
cd ../mods
sudo bash tuned_activate_hpc_compute.sh
```

Este script:

- Activa el perfil `hpc-compute` de Tuned
- Optimiza el sistema para cargas de trabajo de cÃ³mputo intensivo
- Ajusta frecuencias de CPU, schedulers y polÃ­ticas de energÃ­a

**VerificaciÃ³n**:

```bash
sudo tuned-adm active
sudo tuned-adm verify
```

#### 2.2 OptimizaciÃ³n del Kernel

```bash
sudo bash optimize_kernel.sh
```

Este script configura:

**GestiÃ³n de Memoria**:

- `vm.swappiness=10` - Minimiza uso de swap
- `vm.dirty_ratio=40` - Optimiza escritura diferida
- `vm.vfs_cache_pressure=50` - Balance entre cachÃ© y memoria

**Sistema de Archivos**:

- `fs.file-max=2097152` - Aumenta lÃ­mite de archivos abiertos
- I/O scheduler: `deadline`/`mq-deadline`
- Read-ahead: 2048 KB

**Archivos Temporales**:

- tmpfs montado en `/mnt/fast_tmp` (4GB en RAM)
- Usado para archivos intermedios del pipeline

**Backup**: Se crea automÃ¡ticamente en `/etc/sysctl.conf.backup.TIMESTAMP`

**VerificaciÃ³n**:

```bash
sysctl -a | grep -E 'vm.swappiness|vm.dirty'
df -h | grep fast_tmp
```

---

## ğŸ“ Estructura del Proyecto

```
ProjectMetagenomicsUTA_FISEI-FCIAB/
â”‚
â”œâ”€â”€ configurations/          # Scripts de instalaciÃ³n
â”‚   â”œâ”€â”€ install_conda.sh
â”‚   â”œâ”€â”€ install_qiime2.sh
â”‚   â”œâ”€â”€ install_tools.sh
â”‚   â””â”€â”€ install_optimization_tools.sh
â”‚
â”œâ”€â”€ mods/                   # Scripts de optimizaciÃ³n del sistema
â”‚   â”œâ”€â”€ tuned_activate_hpc_compute.sh
â”‚   â””â”€â”€ optimize_kernel.sh
â”‚
â”œâ”€â”€ pipelines/              # Pipelines de anÃ¡lisis
â”‚   â”œâ”€â”€ pipeline1.sh                      # Pipeline bÃ¡sico
â”‚   â”œâ”€â”€ pipeline1_stats.sh                # Con monitoreo de recursos
â”‚   â”œâ”€â”€ pipeline_optimized_parallel.sh    # Optimizado con paralelizaciÃ³n
â”‚   â””â”€â”€ pipeline_optimized_parallel_stats.sh  # Optimizado + monitoreo
â”‚
â”œâ”€â”€ tools/                  # Herramientas auxiliares
â”‚   â”œâ”€â”€ generate_metadata.sh    # Genera metadata.tsv automÃ¡ticamente
â”‚   â”œâ”€â”€ generate_plots.sh       # Genera grÃ¡ficos de mÃ©tricas
â”‚   â””â”€â”€ compare_results.sh      # Compara mÃºltiples proyectos
â”‚
â”œâ”€â”€ custom_config_example.sh    # Plantilla de configuraciÃ³n personalizada
â”‚
â””â”€â”€ README.md
```

### Estructura de un Proyecto Individual

```
/home/proyecto/<nombre_proyecto>/
â”‚
â”œâ”€â”€ raw_sequences/          # Secuencias crudas (FASTQ)
â”‚   â”œâ”€â”€ Crohn/
â”‚   â”‚   â”œâ”€â”€ sample1_1.fq.gz
â”‚   â”‚   â”œâ”€â”€ sample1_2.fq.gz
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ Colitis/
â”‚   â””â”€â”€ Control/
â”‚
â”œâ”€â”€ metadata.tsv            # Metadatos de las muestras
â”‚
â”œâ”€â”€ preproc/               # Secuencias preprocesadas
â”‚   â”œâ”€â”€ Crohn/
â”‚   â”œâ”€â”€ Colitis/
â”‚   â””â”€â”€ Control/
â”‚
â”œâ”€â”€ qiime2_results/        # Resultados de QIIME2
â”‚   â”œâ”€â”€ dada2/            # ASVs y estadÃ­sticas
â”‚   â”œâ”€â”€ phylogeny/        # Ãrboles filogenÃ©ticos
â”‚   â””â”€â”€ core_diversity/   # AnÃ¡lisis de diversidad
â”‚
â”œâ”€â”€ results/               # Visualizaciones (.qzv)
â”‚
â”œâ”€â”€ logs/                  # Logs del pipeline (solo en _stats)
â”‚   â”œâ”€â”€ pipeline_master.log
â”‚   â”œâ”€â”€ timing_summary.csv
â”‚   â””â”€â”€ step_*.log
â”‚
â””â”€â”€ metrics/              # MÃ©tricas detalladas (solo en _stats)
    â”œâ”€â”€ system_summary.csv
    â””â”€â”€ resource_*.csv
```

---

## ğŸ§¬ PreparaciÃ³n de Datos

### Estructura de Datos de Entrada

Los datos deben organizarse en el directorio del proyecto:

```bash
mkdir -p /home/proyecto/<nombre_proyecto>/raw_sequences
```

Las secuencias deben estar organizadas por grupos:

```
raw_sequences/
â”œâ”€â”€ Crohn/
â”‚   â”œâ”€â”€ S1_1.fq.gz      # Forward reads
â”‚   â”œâ”€â”€ S1_2.fq.gz      # Reverse reads
â”‚   â”œâ”€â”€ S2_1.fq.gz
â”‚   â””â”€â”€ S2_2.fq.gz
â”œâ”€â”€ Colitis/
â”‚   â”œâ”€â”€ S3_1.fq.gz
â”‚   â””â”€â”€ S3_2.fq.gz
â””â”€â”€ Control/
    â”œâ”€â”€ S4_1.fq.gz
    â””â”€â”€ S4_2.fq.gz
```

**Requisitos**:

- Archivos paired-end en formato FASTQ comprimido (`.fq.gz`)
- Nomenclatura: `<sample_id>_1.fq.gz` y `<sample_id>_2.fq.gz`
- Organizados en subdirectorios por grupo/condiciÃ³n

### GeneraciÃ³n de Metadata

El archivo `metadata.tsv` es requerido por QIIME2 y se genera automÃ¡ticamente:

```bash
cd tools
bash generate_metadata.sh <nombre_proyecto>
```

**Ejemplo**:

```bash
bash generate_metadata.sh Proyecto_EII_2025
```

El script:

1. Detecta automÃ¡ticamente todos los grupos en `raw_sequences/`
2. Extrae los IDs de las muestras de los archivos `*_1.fq.gz`
3. Genera `metadata.tsv` con formato compatible con QIIME2
4. Verifica que cada muestra tenga su par R1/R2

**Formato generado**:

```tsv
#SampleID	Group
S1	Crohn
S2	Crohn
S3	Colitis
S4	Control
```

**Nota**: Puede editar manualmente este archivo para agregar columnas adicionales (edad, sexo, etc.).

---

## ğŸ”¬ Uso de Pipelines

Todos los pipelines siguen la misma sintaxis bÃ¡sica:

```bash
bash <nombre_pipeline>.sh <nombre_proyecto> [config_file]
```

### Pipeline BÃ¡sico

**Archivo**: `pipeline1.sh`

Pipeline estÃ¡ndar sin monitoreo de recursos.

```bash
cd pipelines
bash pipeline1.sh Proyecto_EII_2025
```

**Pasos ejecutados**:

1. Preprocesamiento con fastp (control de calidad)
2. DADA2 denoising (identificaciÃ³n de ASVs)
3. ConstrucciÃ³n de Ã¡rboles filogenÃ©ticos
4. AnÃ¡lisis de diversidad alfa y beta
5. GeneraciÃ³n de visualizaciones (.qzv)

**Tiempo estimado**: 2-4 horas (15 muestras)

---

### Pipeline con Monitoreo de Recursos

**Archivo**: `pipeline1_stats.sh`

Pipeline con monitoreo completo de recursos computacionales.

```bash
bash pipeline1_stats.sh Proyecto_EII_2025
```

**MÃ©tricas capturadas**:

- â±ï¸ **Tiempo**: DuraciÃ³n por paso y total
- ğŸ’¾ **Memoria**: Uso mÃ¡ximo (KB, MB, GB)
- ğŸ”¥ **CPU**: Porcentaje de utilizaciÃ³n
- ğŸ’¿ **I/O**: Lecturas/escrituras de disco (MB)
- ğŸŒ **Red**: TrÃ¡fico de red (opcional)

**Archivos generados**:

```
logs/
â”œâ”€â”€ pipeline_master.log       # Log consolidado
â”œâ”€â”€ timing_summary.csv        # Resumen de tiempos
â””â”€â”€ step_*.log               # Log individual por paso

metrics/
â”œâ”€â”€ system_summary.csv        # Resumen del sistema
â””â”€â”€ resource_*.csv           # MÃ©tricas detalladas por paso
```

**VisualizaciÃ³n de resultados**:

```bash
cd tools
python3 generate_plots.sh Proyecto_EII_2025
```

---

### Pipeline Optimizado con ParalelizaciÃ³n

**Archivo**: `pipeline_optimized_parallel.sh`

Pipeline optimizado con GNU Parallel y compresiÃ³n paralela.

```bash
bash pipeline_optimized_parallel.sh Proyecto_EII_2025
```

**Optimizaciones aplicadas**:

- âœ… Procesamiento paralelo de muestras con GNU Parallel
- âœ… CompresiÃ³n/descompresiÃ³n paralela con pigz
- âœ… Todas las muestras procesadas juntas en DADA2
- âœ… Uso de tmpfs (`/mnt/fast_tmp`) para archivos temporales

**Variante con estadÃ­sticas**:

```bash
bash pipeline_optimized_parallel_stats.sh Proyecto_EII_2025
```

**Mejoras de rendimiento**:

- ReducciÃ³n de tiempo: ~92.7%
- Mejor utilizaciÃ³n de CPU: 45-60%
- I/O optimizado: Lectura/escritura paralela

---

## ğŸ› ï¸ Herramientas Auxiliares

### 1. GeneraciÃ³n de Metadata

**Script**: `tools/generate_metadata.sh`

Genera automÃ¡ticamente el archivo `metadata.tsv` requerido por QIIME2.

```bash
bash generate_metadata.sh <nombre_proyecto>
```

**Ejemplo**:

```bash
bash generate_metadata.sh Proyecto_20251208
```

**Funcionalidad**:

- Detecta grupos automÃ¡ticamente
- Extrae IDs de muestras de archivos FASTQ
- Verifica pares R1/R2
- Permite confirmaciÃ³n antes de sobrescribir

---

### 2. GeneraciÃ³n de GrÃ¡ficos

**Script**: `tools/generate_plots.sh`

Genera visualizaciones de las mÃ©tricas capturadas por pipelines `_stats`.

```bash
bash generate_plots.sh <nombre_proyecto>
```

**GrÃ¡ficos generados**:

- Tiempo de ejecuciÃ³n por paso
- Uso de memoria por paso
- UtilizaciÃ³n de CPU
- I/O de disco (lectura/escritura)
- Comparativas entre pasos

**Salida**: Archivos PNG en `<proyecto>/metrics/plots/`

**Requisitos**: Python 3 con matplotlib, pandas

---

### 3. ComparaciÃ³n de Proyectos

**Script**: `tools/compare_results.sh`

Compara mÃ©tricas de rendimiento entre mÃºltiples proyectos.

```bash
bash compare_results.sh <proyecto1> <proyecto2> [proyecto3] ...
```

**Ejemplo**:

```bash
bash compare_results.sh Proyecto_Sin_Opt Proyecto_Opt_Kernel Proyecto_Opt_Full
```

**Funcionalidad**:

- Consolida mÃ©tricas de mÃºltiples proyectos
- Genera grÃ¡ficos comparativos
- Calcula mejoras porcentuales
- Identifica cuellos de botella

**Salida**: Directorio `project_comparisons/comparison_TIMESTAMP/`

- `consolidated_metrics.csv`
- GrÃ¡ficos comparativos (PNG)
- Reporte de mejoras (TXT)

---

## âš™ï¸ ConfiguraciÃ³n Personalizada

Puede personalizar los parÃ¡metros del pipeline sin modificar los scripts originales.

### Uso de Archivo de ConfiguraciÃ³n

1. **Copie el archivo de ejemplo**:

```bash
cp custom_config_example.sh mi_configuracion.sh
```

2. **Edite los parÃ¡metros**:

```bash
nano mi_configuracion.sh
```

3. **Ejecute el pipeline con su configuraciÃ³n**:

```bash
bash pipeline1_stats.sh Proyecto_20251208 mi_configuracion.sh
```

### ParÃ¡metros Configurables

#### ParÃ¡metros de fastp (Preprocesamiento)

```bash
FASTP_TRIM_FRONT1=10           # Bases a recortar al inicio (R1)
FASTP_TRIM_FRONT2=10           # Bases a recortar al inicio (R2)
FASTP_QUALITY_PHRED=20         # Calidad mÃ­nima Phred
FASTP_LENGTH_REQUIRED=150      # Longitud mÃ­nima de secuencia
FASTP_THREADS=12               # Hilos para fastp
```

#### ParÃ¡metros de DADA2 (Denoising)

```bash
DADA2_TRIM_LEFT_F=0            # Recorte izquierdo R1
DADA2_TRIM_LEFT_R=0            # Recorte izquierdo R2
DADA2_TRUNC_LEN_F=230          # Longitud de truncamiento R1
DADA2_TRUNC_LEN_R=220          # Longitud de truncamiento R2
DADA2_MAX_EE_F=2.0             # MÃ¡ximo error esperado R1
DADA2_MAX_EE_R=2.0             # MÃ¡ximo error esperado R2
DADA2_THREADS=12               # Hilos para DADA2
```

#### ParÃ¡metros de AnÃ¡lisis de Diversidad

```bash
SAMPLING_DEPTH=6000            # Profundidad de rarefacciÃ³n
PHYLO_THREADS=12               # Hilos para filogenia
```

### Ejemplo de ConfiguraciÃ³n para Servidor de 24 Cores

```bash
#!/usr/bin/env bash

FASTP_THREADS=6
DADA2_THREADS=20
PHYLO_THREADS=20

SAMPLING_DEPTH=8000

DADA2_TRUNC_LEN_F=240
DADA2_TRUNC_LEN_R=230
```

---

## ğŸ“Š ComparaciÃ³n de Resultados

### ComparaciÃ³n entre Configuraciones

Para comparar diferentes estrategias de optimizaciÃ³n:

```bash
bash tools/compare_results.sh Servidor_Actual_Sin_Opt Servidor_Actual_Opt Servidor_Nuevo_Opt
```

### Ejemplo de AnÃ¡lisis

```bash
# 1. Ejecutar pipeline sin optimizaciones
bash pipeline1_stats.sh Baseline

# 2. Aplicar optimizaciones de kernel
sudo bash mods/optimize_kernel.sh
bash pipeline1_stats.sh Kernel_Opt

# 3. Usar pipeline optimizado
bash pipeline_optimized_parallel_stats.sh Full_Opt

# 4. Comparar resultados
bash tools/compare_results.sh Baseline Kernel_Opt Full_Opt
```

### MÃ©tricas de ComparaciÃ³n

El script genera:

- **GrÃ¡ficos de tiempo**: ComparaciÃ³n de duraciÃ³n por paso
- **GrÃ¡ficos de memoria**: Uso mÃ¡ximo de RAM
- **GrÃ¡ficos de CPU**: UtilizaciÃ³n porcentual
- **GrÃ¡ficos de I/O**: Velocidad de lectura/escritura
- **Tabla de mejoras**: Porcentajes de optimizaciÃ³n

---

## ğŸš€ Optimizaciones Implementadas

### Nivel 1: OptimizaciÃ³n de Kernel

**Script**: `mods/optimize_kernel.sh`

- ReducciÃ³n de swappiness (vm.swappiness=10)
- OptimizaciÃ³n de escritura diferida (dirty_ratio=40)
- Aumento de lÃ­mite de archivos abiertos
- ConfiguraciÃ³n de I/O scheduler (deadline/mq-deadline)
- tmpfs de 4GB para archivos temporales

**Impacto**: 15-25% reducciÃ³n de tiempo

### Nivel 2: Herramientas de ParalelizaciÃ³n

**Script**: `configurations/install_optimization_tools.sh`

- GNU Parallel para ejecuciÃ³n paralela de tareas
- pigz para compresiÃ³n/descompresiÃ³n paralela
- Reemplazo automÃ¡tico de gzip por pigz

**Impacto**: 30-45% reducciÃ³n de tiempo

### Nivel 3: Perfil HPC Compute

**Script**: `mods/tuned_activate_hpc_compute.sh`

- OptimizaciÃ³n de frecuencias de CPU
- PolÃ­ticas de energÃ­a para rendimiento
- Schedulers optimizados para HPC

**Impacto**: 10-20% reducciÃ³n de tiempo

### Nivel 4: Pipeline Optimizado

**Script**: `pipeline_optimized_parallel.sh`

- Procesamiento paralelo de muestras (GNU Parallel)
- Todas las muestras procesadas juntas en DADA2
- Uso de tmpfs para archivos intermedios
- CompresiÃ³n paralela con pigz

**Impacto combinado**: **92.7% reducciÃ³n de tiempo**

---

## ğŸ“ˆ Resultados

### Servidor Actual (12 cores, 32 GB RAM)

| ConfiguraciÃ³n     | Tiempo Total   | Mejora    |
| ----------------- | -------------- | --------- |
| Sin optimizar     | ~8-10 horas    | -         |
| Kernel optimizado | ~6-7 horas     | 25%       |
| Full optimizado   | ~35-45 minutos | **92.7%** |

### Servidor Nuevo (24 cores, 64 GB RAM)

| ConfiguraciÃ³n     | Tiempo Total   | Mejora    |
| ----------------- | -------------- | --------- |
| Sin optimizar     | ~4-5 horas     | -         |
| Kernel optimizado | ~3-3.5 horas   | 30%       |
| Full optimizado   | ~18-25 minutos | **93.5%** |

### MÃ©tricas de UtilizaciÃ³n

**Sin optimizar**:

- CPU: 15-25%
- Memoria: ~8 GB
- I/O: Secuencial

**Optimizado**:

- CPU: 45-60%
- Memoria: ~12-16 GB
- I/O: Paralelo (pigz)

---

## ğŸ› Troubleshooting

### Problema: Error de permisos

**Error**: `Permission denied`

**SoluciÃ³n**:

```bash
# Verificar pertenencia al grupo research
groups

# Si no estÃ¡ en el grupo, agregarse
sudo usermod -aG research $USER

# Cerrar sesiÃ³n y volver a entrar
```

### Problema: Conda no encontrado despuÃ©s de instalaciÃ³n

**Error**: `conda: command not found`

**SoluciÃ³n**:

```bash
# Reinicializar conda
source /opt/conda/etc/profile.d/conda.sh
conda init bash

# Cerrar y reabrir terminal
```

### Problema: QIIME2 falla con error de memoria

**Error**: `MemoryError` o `Killed`

**SoluciÃ³n**:

```bash
# Reducir profundidad de muestreo
echo "SAMPLING_DEPTH=4000" >> custom_config.sh

# Reducir hilos de DADA2
echo "DADA2_THREADS=8" >> custom_config.sh

# Ejecutar con configuraciÃ³n personalizada
bash pipeline1_stats.sh MiProyecto custom_config.sh
```

### Problema: Archivos .qzv no se generan

**Error**: Missing `.qzv` files

**SoluciÃ³n**:

```bash
# Verificar que metadata.tsv existe y es vÃ¡lido
cat /home/proyecto/MiProyecto/metadata.tsv

# Verificar que hay resultados de DADA2
ls -lh /home/proyecto/MiProyecto/qiime2_results/dada2/

# Regenerar metadata si es necesario
bash tools/generate_metadata.sh MiProyecto
```

### Problema: GNU Parallel muestra warning de citaciÃ³n

**Warning**: `citation` warning

**SoluciÃ³n**:

```bash
# El script install_optimization_tools.sh ya crea este archivo
# Si persiste, ejecutar manualmente:
mkdir -p ~/.parallel
touch ~/.parallel/will-cite
```

### Problema: pigz no reemplaza gzip

**SÃ­ntoma**: Sigue usando gzip estÃ¡ndar

**SoluciÃ³n**:

```bash
# Verificar alias
alias | grep gzip

# Si no aparece, cargar perfil
source /etc/profile.d/bioinformatics_optimizations.sh

# Verificar nuevamente
which gzip  # Debe apuntar a pigz
```

### Problema: tmpfs no estÃ¡ montado

**Error**: `/mnt/fast_tmp: No such file or directory`

**SoluciÃ³n**:

```bash
# Verificar si estÃ¡ en fstab
grep fast_tmp /etc/fstab

# Si no estÃ¡, ejecutar optimize_kernel.sh nuevamente
sudo bash mods/optimize_kernel.sh

# Montar manualmente si es necesario
sudo mkdir -p /mnt/fast_tmp
sudo mount -t tmpfs -o size=4G tmpfs /mnt/fast_tmp
```

---

## ğŸ“š Referencias

### Software y Herramientas

- **QIIME2** (2024.10): [https://qiime2.org/](https://qiime2.org/)
- **fastp**: Chen et al. (2018). [doi:10.1093/bioinformatics/bty560](https://doi.org/10.1093/bioinformatics/bty560)
- **GNU Parallel**: Tange (2022). [doi:10.5281/zenodo.1146014](https://doi.org/10.5281/zenodo.1146014)
- **pigz**: [https://zlib.net/pigz/](https://zlib.net/pigz/)

### MetodologÃ­a BioinformÃ¡tica

- **DADA2**: Callahan et al. (2016). "DADA2: High-resolution sample inference from Illumina amplicon data". _Nature Methods_, 13(7), 581-583. [doi:10.1038/nmeth.3869](https://doi.org/10.1038/nmeth.3869)

- **AnÃ¡lisis de diversidad**: Lozupone & Knight (2005). "UniFrac: a new phylogenetic method for comparing microbial communities". _Applied and Environmental Microbiology_, 71(12), 8228-8235. [doi:10.1128/AEM.71.12.8228-8235.2005](https://doi.org/10.1128/AEM.71.12.8228-8235.2005)

### OptimizaciÃ³n Computacional

- **Kernel optimization for bioinformatics**: Kumar et al. (2021). "Performance optimization of bioinformatics applications on HPC systems". _BMC Bioinformatics_, 22(1), 1-18. [doi:10.1186/s12859-021-04089-5](https://doi.org/10.1186/s12859-021-04089-5)

- **Parallel processing in genomics**: Schmidt & Hildebrandt (2021). "Opportunities and Challenges in Applying Parallel and Distributed Computing to Genomics". _Frontiers in Genetics_, 12. [doi:10.3389/fgene.2021.659687](https://doi.org/10.3389/fgene.2021.659687)

### Proyecto de InvestigaciÃ³n

- **Universidad TÃ©cnica de Ambato** - Proyecto: "Estrategias MetagenÃ³micas para caracterizaciÃ³n del microbioma intestinal humano aplicado al diagnÃ³stico precoz y tratamiento personalizado de las Enfermedades Inflamatorias Intestinales (EII)"

---

## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT. Ver archivo `LICENSE` para mÃ¡s detalles.

---

## ğŸ‘¨â€ğŸ’» Autor

**Mateo Zurita**  
Universidad TÃ©cnica de Ambato  
Facultad de IngenierÃ­a en Sistemas, ElectrÃ³nica e Industrial  
Carrera de Software

**Contacto**: [GitHub](https://github.com/mateozu13)

---

## ğŸ™ Agradecimientos

- Universidad TÃ©cnica de Ambato - FISEI
- Proyecto de InvestigaciÃ³n EII
- Comunidad QIIME2
- Comunidad de bioinformÃ¡tica de cÃ³digo abierto

---

## ğŸ“… Ãšltima ActualizaciÃ³n

Diciembre 2025 - VersiÃ³n 1.0.0

---

## ğŸ”„ Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el proyecto
2. Cree una rama para su feature (`git checkout -b feature/NuevaCaracteristica`)
3. Commit sus cambios (`git commit -m 'Agregar nueva caracterÃ­stica'`)
4. Push a la rama (`git push origin feature/NuevaCaracteristica`)
5. Abra un Pull Request

---

## ğŸ“Š Estado del Proyecto

![Status](https://img.shields.io/badge/Status-Active-success)
![Maintenance](https://img.shields.io/badge/Maintained-Yes-green.svg)
![Version](https://img.shields.io/badge/Version-1.0.0-blue.svg)

**Ãšltima ejecuciÃ³n exitosa**: Diciembre 2025  
**Tests pasados**: âœ… Todos  
**DocumentaciÃ³n**: âœ… Completa
